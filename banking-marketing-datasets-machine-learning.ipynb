{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center style=\"color:red;font-size:50px;font-family:courier\">Prediction Of Banking  Marketing  Using Machine Learning  </center>\n","metadata":{}},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'>Import Libraries</h1></center>\n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport time\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # for EDA\nimport matplotlib.pyplot as plt # for EDA\nimport scipy.stats as stats # for statistical calculations\nfrom sklearn.model_selection import train_test_split#for spilting data into train and test\nfrom sklearn.preprocessing import LabelEncoder # for converting label data to integer\nfrom sklearn.preprocessing import StandardScaler #for converting data into format\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score #confusion matrix\n\n#bagging algorithms\nfrom sklearn.linear_model import LogisticRegression # for logistic regression\nfrom sklearn.svm import SVC# for svc classifier\nfrom sklearn.tree import DecisionTreeClassifier # for decision tree classifier\nfrom sklearn.naive_bayes import GaussianNB  # naive bayes classifier\nfrom sklearn.neighbors import KNeighborsClassifier  # for k neighbours classifier\n\n\n#boosting algorithms\n\nfrom sklearn.ensemble import RandomForestClassifier  #random Forest\nfrom sklearn.ensemble import AdaBoostClassifier  # ada boost classifier\nfrom sklearn.ensemble import GradientBoostingClassifier  #gradient boosting\n\n\n#sunsupervised learning\nfrom sklearn.cluster import KMeans \n\n#sampling data\nfrom imblearn.over_sampling import RandomOverSampler  # sampling datapoints\n\nfrom sklearn.model_selection import KFold #k fold for training data\n\nfrom sklearn.decomposition import PCA # principle componet analysis\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\nsns.set_style('darkgrid')\nsns.set_palette('Set2')\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(\"model loaded\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'>Import datasets</h1></center>\n","metadata":{}},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/bank-marketing-dataset/bank/bank.csv\",delimiter=';')# importing datasets\nfdata=pd.read_csv(\"/kaggle/input/bank-marketing-dataset/bank/bank-full.csv\",delimiter=\";\")","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:54.495760Z","iopub.execute_input":"2023-07-12T04:56:54.496117Z","iopub.status.idle":"2023-07-12T04:56:54.679178Z","shell.execute_reply.started":"2023-07-12T04:56:54.496089Z","shell.execute_reply":"2023-07-12T04:56:54.677931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fdata.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:54.680483Z","iopub.execute_input":"2023-07-12T04:56:54.680819Z","iopub.status.idle":"2023-07-12T04:56:54.702412Z","shell.execute_reply.started":"2023-07-12T04:56:54.680789Z","shell.execute_reply":"2023-07-12T04:56:54.701156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Full data length\",fdata.shape)#shape of dataset\nprint(\"Data length\",data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:54.705759Z","iopub.execute_input":"2023-07-12T04:56:54.706120Z","iopub.status.idle":"2023-07-12T04:56:54.712337Z","shell.execute_reply.started":"2023-07-12T04:56:54.706090Z","shell.execute_reply":"2023-07-12T04:56:54.711050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"afdata=pd.read_csv(\"/kaggle/input/bank-marketing-dataset/bank-additional/bank-additional/bank-additional-full.csv\",delimiter=\";\")","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:54.714094Z","iopub.execute_input":"2023-07-12T04:56:54.715154Z","iopub.status.idle":"2023-07-12T04:56:54.897722Z","shell.execute_reply.started":"2023-07-12T04:56:54.715108Z","shell.execute_reply":"2023-07-12T04:56:54.896565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"addition data shape\",afdata.shape)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:54.899452Z","iopub.execute_input":"2023-07-12T04:56:54.899805Z","iopub.status.idle":"2023-07-12T04:56:54.907848Z","shell.execute_reply.started":"2023-07-12T04:56:54.899775Z","shell.execute_reply":"2023-07-12T04:56:54.906625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"afdata.columns  #columns present into the datsets","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:54.909486Z","iopub.execute_input":"2023-07-12T04:56:54.909788Z","iopub.status.idle":"2023-07-12T04:56:54.922933Z","shell.execute_reply.started":"2023-07-12T04:56:54.909762Z","shell.execute_reply":"2023-07-12T04:56:54.921495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if list(data.columns)==list(data.columns):\n    print(\"Both have same columns\")\n    data=pd.concat([fdata,data],axis=0)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:54.925042Z","iopub.execute_input":"2023-07-12T04:56:54.925521Z","iopub.status.idle":"2023-07-12T04:56:54.948404Z","shell.execute_reply.started":"2023-07-12T04:56:54.925480Z","shell.execute_reply":"2023-07-12T04:56:54.947076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'>Data processing and cleaning</h1></center>\n","metadata":{}},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:54.952467Z","iopub.execute_input":"2023-07-12T04:56:54.952825Z","iopub.status.idle":"2023-07-12T04:56:54.960273Z","shell.execute_reply.started":"2023-07-12T04:56:54.952795Z","shell.execute_reply":"2023-07-12T04:56:54.959104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the duplicates values into the datasets\ndata.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:54.962402Z","iopub.execute_input":"2023-07-12T04:56:54.962813Z","iopub.status.idle":"2023-07-12T04:56:55.039437Z","shell.execute_reply.started":"2023-07-12T04:56:54.962773Z","shell.execute_reply":"2023-07-12T04:56:55.038192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fdata.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:55.041028Z","iopub.execute_input":"2023-07-12T04:56:55.041393Z","iopub.status.idle":"2023-07-12T04:56:55.101522Z","shell.execute_reply.started":"2023-07-12T04:56:55.041362Z","shell.execute_reply":"2023-07-12T04:56:55.100430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fdata.describe()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:55.103066Z","iopub.execute_input":"2023-07-12T04:56:55.103405Z","iopub.status.idle":"2023-07-12T04:56:55.945192Z","shell.execute_reply.started":"2023-07-12T04:56:55.103376Z","shell.execute_reply":"2023-07-12T04:56:55.943988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fdata.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:55.946771Z","iopub.execute_input":"2023-07-12T04:56:55.947159Z","iopub.status.idle":"2023-07-12T04:56:56.103406Z","shell.execute_reply.started":"2023-07-12T04:56:55.947128Z","shell.execute_reply":"2023-07-12T04:56:56.102147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum()#checking null values into the datasets","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:56.104998Z","iopub.execute_input":"2023-07-12T04:56:56.105460Z","iopub.status.idle":"2023-07-12T04:56:56.273106Z","shell.execute_reply.started":"2023-07-12T04:56:56.105425Z","shell.execute_reply":"2023-07-12T04:56:56.272106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'>Exploratory Data analysis</h1></center>\n","metadata":{}},{"cell_type":"code","source":"job_lists=dict(fdata['job'].value_counts())\n\nvalues=list(job_lists.values())\nprint(values)\n\nkeys=list(job_lists.keys())\nprint(keys)\n\nplt.figure(figsize=(10,5))\n#for the barplots plotting\nplt.bar(keys, values, color ='maroon',\n        width = 0.4)\n \nplt.xticks(rotation = 45) # for x axis rotations\nplt.title(\"COUNT OF CUSTOMERS PROFESSION\")\n \nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:56.274343Z","iopub.execute_input":"2023-07-12T04:56:56.274696Z","iopub.status.idle":"2023-07-12T04:56:56.710677Z","shell.execute_reply.started":"2023-07-12T04:56:56.274664Z","shell.execute_reply":"2023-07-12T04:56:56.709047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Most of the customers are from blue colllar management and technician**","metadata":{}},{"cell_type":"code","source":"marital_lists=dict(fdata['marital'].value_counts())\n\nvalues=list(marital_lists.values())\nprint(values)\n\nkeys=list(marital_lists.keys())\nprint(keys)\n\nplt.figure(figsize=(10,5))\nplt.bar(keys, values, color ='maroon',\n        width = 0.4)\n \nplt.xticks(rotation = 45) \nplt.title(\"COUNT OF MARITAL STATUS \")\n \nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:56.712376Z","iopub.execute_input":"2023-07-12T04:56:56.713225Z","iopub.status.idle":"2023-07-12T04:56:57.018269Z","shell.execute_reply.started":"2023-07-12T04:56:56.713179Z","shell.execute_reply":"2023-07-12T04:56:57.016867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Most of the customers are married and single .**","metadata":{}},{"cell_type":"code","source":"education_lists=dict(fdata['education'].value_counts())\n\nvalues=list(education_lists.values())\nprint(values)\n\nkeys=list(education_lists.keys())\nprint(keys)\n\nplt.figure(figsize=(10,5))\nplt.bar(keys, values, color ='maroon',\n        width = 0.4)\n \nplt.xticks(rotation = 45) \nplt.title(\"COUNT OF EDUCATION STATUS \")\n \nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:57.019693Z","iopub.execute_input":"2023-07-12T04:56:57.020047Z","iopub.status.idle":"2023-07-12T04:56:57.330822Z","shell.execute_reply.started":"2023-07-12T04:56:57.019987Z","shell.execute_reply":"2023-07-12T04:56:57.329441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Customers have high percentage in seconadary degree than ternary and primary**","metadata":{}},{"cell_type":"code","source":"target=fdata[fdata['y']==\"yes\"]\nnot_targeted=fdata[fdata['y']=='no']","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:57.332466Z","iopub.execute_input":"2023-07-12T04:56:57.332840Z","iopub.status.idle":"2023-07-12T04:56:57.368905Z","shell.execute_reply.started":"2023-07-12T04:56:57.332808Z","shell.execute_reply":"2023-07-12T04:56:57.367482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.histplot(target['age'],label=\"target\")\nsns.histplot(not_targeted['age'],label=\"not target\")\nplt.legend()\nplt.title(\"HISTPLOT FOR TARGETED AND NON TARGETED\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:57.370600Z","iopub.execute_input":"2023-07-12T04:56:57.370981Z","iopub.status.idle":"2023-07-12T04:56:58.199786Z","shell.execute_reply.started":"2023-07-12T04:56:57.370949Z","shell.execute_reply":"2023-07-12T04:56:58.198691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\n\nlist_names=['job','education']\n\nj=1\n\nfor i in list_names:\n    plt.subplot(1,2,j)\n    education_lists=dict(target[i].value_counts())\n\n    values=list(education_lists.values())\n\n\n    keys=list(education_lists.keys())\n\n\n   # plt.figure(figsize=(10,5))\n    plt.bar(keys, values, color ='green',\n        width = 0.4)\n \n    plt.xticks(rotation = 45) \n    plt.title(\"count of {} for targetd values\".format(i))\n    j=j+1\n \n   ","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:58.201221Z","iopub.execute_input":"2023-07-12T04:56:58.201541Z","iopub.status.idle":"2023-07-12T04:56:58.944178Z","shell.execute_reply.started":"2023-07-12T04:56:58.201513Z","shell.execute_reply":"2023-07-12T04:56:58.943213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Targeted custmer have management and technician and blue collar customers and their educations percentage is secondart,ternary,primary respectively**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\n\nlist_names=['job','education']\n\nj=1\n\nfor i in list_names:\n    plt.subplot(1,2,j)\n    education_lists=dict(not_targeted[i].value_counts())\n\n    values=list(education_lists.values())\n\n\n    keys=list(education_lists.keys())\n\n\n   # plt.figure(figsize=(10,5))\n    plt.bar(keys, values, color ='black',\n        width = 0.4)\n \n    plt.xticks(rotation = 45) \n    plt.title(\"count of {} for not targetd values\".format(i))\n    j=j+1\n ","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:58.945837Z","iopub.execute_input":"2023-07-12T04:56:58.946215Z","iopub.status.idle":"2023-07-12T04:56:59.715509Z","shell.execute_reply.started":"2023-07-12T04:56:58.946184Z","shell.execute_reply":"2023-07-12T04:56:59.714458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\n\nlist_names=['marital','month']\n\nj=1\n\nfor i in list_names:\n    plt.subplot(1,2,j)\n    education_lists=dict(target[i].value_counts())\n\n    values=list(education_lists.values())\n\n\n    keys=list(education_lists.keys())\n\n\n   # plt.figure(figsize=(10,5))\n    plt.bar(keys, values, color ='green',\n        width = 0.4)\n \n    plt.xticks(rotation = 45) \n    plt.title(\"count of {} for targetd values\".format(i))\n    j=j+1\n ","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:56:59.716997Z","iopub.execute_input":"2023-07-12T04:56:59.717355Z","iopub.status.idle":"2023-07-12T04:57:00.466814Z","shell.execute_reply.started":"2023-07-12T04:56:59.717325Z","shell.execute_reply":"2023-07-12T04:57:00.465426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**May aug july and aprial  months have highest customer joinings**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\n\nlist_names=['marital','month']\n\nj=1\n\nfor i in list_names:\n    plt.subplot(1,2,j)\n    education_lists=dict(not_targeted[i].value_counts())\n\n    values=list(education_lists.values())\n\n\n    keys=list(education_lists.keys())\n\n\n   # plt.figure(figsize=(10,5))\n    plt.bar(keys, values, color ='black',\n        width = 0.4)\n \n    plt.xticks(rotation = 45) \n    plt.title(\"count of {} for not targetd values\".format(i))\n    j=j+1\n ","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:00.468609Z","iopub.execute_input":"2023-07-12T04:57:00.469054Z","iopub.status.idle":"2023-07-12T04:57:01.215487Z","shell.execute_reply.started":"2023-07-12T04:57:00.468995Z","shell.execute_reply":"2023-07-12T04:57:01.214172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.scatterplot(target[target['default']==\"yes\"]['balance'].head(10000),label=\"targeted\")\nsns.scatterplot(not_targeted[not_targeted['default']==\"yes\"]['balance'].head(10000),label=\"not targeted\")\nplt.title(\"DEFAULT CUSTOMERS\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:01.225759Z","iopub.execute_input":"2023-07-12T04:57:01.226548Z","iopub.status.idle":"2023-07-12T04:57:01.703720Z","shell.execute_reply.started":"2023-07-12T04:57:01.226514Z","shell.execute_reply":"2023-07-12T04:57:01.702312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.scatterplot(target[target['default']==\"no\"]['balance'].head(10000),label=\"targeted\")\nsns.scatterplot(not_targeted[not_targeted['default']==\"no\"]['balance'].head(10000),label=\"not targeted\")\nplt.title(\"NON DEFAULT CUSTOMERS\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:01.706024Z","iopub.execute_input":"2023-07-12T04:57:01.706957Z","iopub.status.idle":"2023-07-12T04:57:02.427442Z","shell.execute_reply.started":"2023-07-12T04:57:01.706893Z","shell.execute_reply":"2023-07-12T04:57:02.426187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\ntarget['contact'].value_counts().plot(kind='bar')\nplt.title(\"CAONTACT INFO OF TARGET CUSTOMERS\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:02.429102Z","iopub.execute_input":"2023-07-12T04:57:02.430033Z","iopub.status.idle":"2023-07-12T04:57:02.766911Z","shell.execute_reply.started":"2023-07-12T04:57:02.429984Z","shell.execute_reply":"2023-07-12T04:57:02.765637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Customers have higher percentage of celluar data**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nfdata['y'].value_counts().plot(kind='bar')\nplt.title(\"TARGET COLUMNS VALUE COUNTS\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:02.768837Z","iopub.execute_input":"2023-07-12T04:57:02.771346Z","iopub.status.idle":"2023-07-12T04:57:03.147959Z","shell.execute_reply.started":"2023-07-12T04:57:02.771302Z","shell.execute_reply":"2023-07-12T04:57:03.145721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**This barplots shows the target variables are not distributed uniformaly. Not targeted customer have higher counts**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.histplot(target['duration'])\nplt.title(\"HISTPLOT FOR DURATION(TARGETD)\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:03.149852Z","iopub.execute_input":"2023-07-12T04:57:03.150215Z","iopub.status.idle":"2023-07-12T04:57:03.792992Z","shell.execute_reply.started":"2023-07-12T04:57:03.150185Z","shell.execute_reply":"2023-07-12T04:57:03.790394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.histplot(not_targeted['duration'])\nplt.title(\"HISTPLOT FOR DURATION(NON-TARGETD)\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:03.794859Z","iopub.execute_input":"2023-07-12T04:57:03.795221Z","iopub.status.idle":"2023-07-12T04:57:05.161057Z","shell.execute_reply.started":"2023-07-12T04:57:03.795190Z","shell.execute_reply":"2023-07-12T04:57:05.159733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Identify outliers","metadata":{}},{"cell_type":"markdown","source":"**outliers refer to data points or observations that significantly deviate from the majority of the data points in a dataset. They are unusual or extreme values that do not follow the expected pattern or distribution of the data. Outliers can occur due to various reasons such as measurement errors, data entry mistakes, or genuinely unusual phenomena.**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\n\nj=1\nfor col in fdata.columns:\n    if fdata[col].dtype==\"int64\":\n        if col==\"balance\" or col==\"duration\":\n            \n            plt.subplot(1,2,j)\n            sns.boxplot((fdata[col]),color=\"red\");\n            plt.title(\"THE VARIANCE VALUES OF {} \".format(col))\n            j=j+1\n                \n                ","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:05.162555Z","iopub.execute_input":"2023-07-12T04:57:05.162896Z","iopub.status.idle":"2023-07-12T04:57:05.687341Z","shell.execute_reply.started":"2023-07-12T04:57:05.162868Z","shell.execute_reply":"2023-07-12T04:57:05.685967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**In statistics, the z-score (or standard score) is a measure that indicates how many standard deviations a particular data point is away from the mean of a distribution. It allows you to standardize and compare data points from different distributions, making it useful for identifying outliers or determining the relative position of a value within a dataset.**\n\n**The formula to calculate the z-score for a data point, x, in a dataset with a mean, μ, and standard deviation, σ, is:**\n\n**z = (x - μ) / σ**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\n\nj=1\nfor col in fdata.columns:\n    if fdata[col].dtype==\"int64\":\n        if col==\"balance\" or col==\"duration\":\n            \n            plt.subplot(1,2,j)\n            sns.boxplot(stats.zscore(fdata[col]),color=\"red\");\n            plt.title(\"THE ZSCORE VALUES OF {} \".format(col))\n            j=j+1\n                \n                \n            ","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:05.689043Z","iopub.execute_input":"2023-07-12T04:57:05.689398Z","iopub.status.idle":"2023-07-12T04:57:06.255143Z","shell.execute_reply.started":"2023-07-12T04:57:05.689369Z","shell.execute_reply":"2023-07-12T04:57:06.253777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There are several approaches to detecting outliers in data:**\n\n**Visual inspection: Plotting the data using graphs or scatter plots can sometimes reveal outliers that appear as distinct points that are far away from the majority of the data.**\n\n**Statistical methods: Statistical techniques such as the z-score, modified z-score, or percentile-based methods can be used to identify observations that fall outside a specified range or have extreme values compared to the rest of the data.**\n\n**Machine learning algorithms: Some machine learning algorithms, such as clustering or anomaly detection methods, can be used to automatically identify outliers based on the patterns and structures they learn from the data**","metadata":{}},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'>Data spilting</h1></center>\n","metadata":{}},{"cell_type":"code","source":"x=data.drop(\"y\",axis=1)\ny=data['y']","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:06.256887Z","iopub.execute_input":"2023-07-12T04:57:06.257283Z","iopub.status.idle":"2023-07-12T04:57:06.273667Z","shell.execute_reply.started":"2023-07-12T04:57:06.257252Z","shell.execute_reply":"2023-07-12T04:57:06.272283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The train-test split is important for several reasons:**\n\n**Performance Evaluation: By assessing the model's performance on an independent test set, you can get an estimate of its predictive accuracy and understand how well it is likely to perform on unseen data.**\n\n**Overfitting Detection: The train-test split helps in detecting overfitting, which occurs when a model performs very well on the training data but fails to generalize to new data. If the model's performance on the test set is significantly worse than on the training set, it suggests overfitting.**\n\n**Hyperparameter Tuning: The train-test split is often used during the process of hyperparameter tuning. Hyperparameters are configuration settings of the machine learning algorithm that cannot be learned from the data. By evaluating different hyperparameter choices on the test set, you can select the set of hyperparameters that leads to the best performance.**","metadata":{}},{"cell_type":"code","source":"#training and testing the data \nx_train,x_test,y_train,y_test=train_test_split(x,y,random_state=1,test_size=0.20)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:06.275544Z","iopub.execute_input":"2023-07-12T04:57:06.275914Z","iopub.status.idle":"2023-07-12T04:57:06.312139Z","shell.execute_reply.started":"2023-07-12T04:57:06.275882Z","shell.execute_reply":"2023-07-12T04:57:06.311017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:06.313625Z","iopub.execute_input":"2023-07-12T04:57:06.313956Z","iopub.status.idle":"2023-07-12T04:57:06.333559Z","shell.execute_reply.started":"2023-07-12T04:57:06.313928Z","shell.execute_reply":"2023-07-12T04:57:06.332063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'>Label Encoding</h1></center>\n","metadata":{}},{"cell_type":"markdown","source":"**Label encoding is a technique used in machine learning to convert categorical or textual data into numerical form. In many machine learning algorithms, numerical data is required for training models, and label encoding provides a way to represent categorical variables as integers.**","metadata":{}},{"cell_type":"code","source":"encoder=LabelEncoder()\nfor col in x_train.columns:\n    if x_train[col].dtype==\"object\":\n        x_train[col]=encoder.fit_transform(x_train[col])\n       # x_test[col]=encoder.fit_transform(x_test[col])\n        ","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:06.335753Z","iopub.execute_input":"2023-07-12T04:57:06.336261Z","iopub.status.idle":"2023-07-12T04:57:06.502805Z","shell.execute_reply.started":"2023-07-12T04:57:06.336219Z","shell.execute_reply":"2023-07-12T04:57:06.501502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in x_test.columns:\n    if x_test[col].dtype==\"object\":\n       # x_train[col]=encoder.fit_transform(x_train[col])\n        x_test[col]=encoder.fit_transform(x_test[col])","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:06.504818Z","iopub.execute_input":"2023-07-12T04:57:06.505291Z","iopub.status.idle":"2023-07-12T04:57:06.554250Z","shell.execute_reply.started":"2023-07-12T04:57:06.505247Z","shell.execute_reply":"2023-07-12T04:57:06.552867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train=encoder.fit_transform(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:06.556013Z","iopub.execute_input":"2023-07-12T04:57:06.556768Z","iopub.status.idle":"2023-07-12T04:57:06.578763Z","shell.execute_reply.started":"2023-07-12T04:57:06.556726Z","shell.execute_reply":"2023-07-12T04:57:06.576970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test=encoder.fit_transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:06.580554Z","iopub.execute_input":"2023-07-12T04:57:06.581000Z","iopub.status.idle":"2023-07-12T04:57:06.594383Z","shell.execute_reply.started":"2023-07-12T04:57:06.580965Z","shell.execute_reply":"2023-07-12T04:57:06.593399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:06.596233Z","iopub.execute_input":"2023-07-12T04:57:06.596886Z","iopub.status.idle":"2023-07-12T04:57:06.620964Z","shell.execute_reply.started":"2023-07-12T04:57:06.596724Z","shell.execute_reply":"2023-07-12T04:57:06.619380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.boxplot(x_train)\nplt.xticks(rotation=45)\nplt.title(\"Features before standard scalling\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:06.622718Z","iopub.execute_input":"2023-07-12T04:57:06.623098Z","iopub.status.idle":"2023-07-12T04:57:07.501372Z","shell.execute_reply.started":"2023-07-12T04:57:06.623068Z","shell.execute_reply":"2023-07-12T04:57:07.500085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'>Standard Scalling</h1></center>\n","metadata":{}},{"cell_type":"markdown","source":"**Standard scaling, also known as standardization or z-score normalization, is a data preprocessing technique used to transform numerical features in a dataset to have zero mean and unit variance. It rescales the data so that each feature has a similar scale and distribution, which can be beneficial for certain machine learning algorithms and analyses.\nThe standard scaling process involves the following steps:\nCalculate the mean (μ) and standard deviation (σ) of each feature in the dataset.\nFor each data point in a specific feature, subtract the mean of that feature from the data point, and then divide the result by the standard deviation.**\n\n**The formula for standard scaling a data point, x, in a feature with mean μ and standard deviation σ is:**\n\n**z = (x - μ) / σ**\n\n**The resulting z-score (z) represents the number of standard deviations that a particular data point is away from the mean of the feature.**","metadata":{}},{"cell_type":"code","source":"scaler=StandardScaler()\n\nx_train=pd.DataFrame(scaler.fit_transform(x_train),columns=x_train.columns)\nx_test=pd.DataFrame(scaler.fit_transform(x_test),columns=x_train.columns)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:07.503183Z","iopub.execute_input":"2023-07-12T04:57:07.503653Z","iopub.status.idle":"2023-07-12T04:57:07.532450Z","shell.execute_reply.started":"2023-07-12T04:57:07.503611Z","shell.execute_reply":"2023-07-12T04:57:07.531067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.boxplot(x_train)\nplt.xticks(rotation=45)\nplt.title(\"Features after standard scalling\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:07.534197Z","iopub.execute_input":"2023-07-12T04:57:07.535460Z","iopub.status.idle":"2023-07-12T04:57:08.410262Z","shell.execute_reply.started":"2023-07-12T04:57:07.535416Z","shell.execute_reply":"2023-07-12T04:57:08.409079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy=[] # list for accuarcy\nalgo_name=[] # list for algorithms \ntime_dict={} # dictionary for time period","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:08.411947Z","iopub.execute_input":"2023-07-12T04:57:08.412311Z","iopub.status.idle":"2023-07-12T04:57:08.418360Z","shell.execute_reply.started":"2023-07-12T04:57:08.412281Z","shell.execute_reply":"2023-07-12T04:57:08.417102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'>Logistic Regression</h1></center>\n","metadata":{}},{"cell_type":"markdown","source":"**Logistic regression is a supervised machine learning algorithm used for binary classification tasks. It models the relationship between a set of independent variables (features) and a binary dependent variable (target variable) by estimating the probability of the target variable belonging to a particular class.**\n\n**The logistic regression algorithm uses the logistic function, also known as the sigmoid function, to model the relationship between the features and the probability of the target variable being in a certain class. The sigmoid function maps any real-valued number to a value between 0 and 1, representing the probability.**\n\n**The logistic function is defined as:**\n\n**f(x) = 1 / (1 + e^(-x))**","metadata":{}},{"cell_type":"code","source":"start = time.time()\n\nlog_model= LogisticRegression(random_state=0)  \n\nlog_model.fit(x_train, y_train)  \n\nprint(log_model.score(x_test,y_test))\n\nend=time.time()\n\nprint(\"Time required for code is\",end-start)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:08.419980Z","iopub.execute_input":"2023-07-12T04:57:08.420788Z","iopub.status.idle":"2023-07-12T04:57:08.535433Z","shell.execute_reply.started":"2023-07-12T04:57:08.420742Z","shell.execute_reply":"2023-07-12T04:57:08.533915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_dict['logistic regression']=end-start","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:08.537554Z","iopub.execute_input":"2023-07-12T04:57:08.538616Z","iopub.status.idle":"2023-07-12T04:57:08.550628Z","shell.execute_reply.started":"2023-07-12T04:57:08.538559Z","shell.execute_reply":"2023-07-12T04:57:08.548648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy.append(log_model.score(x_test,y_test))\nalgo_name.append(\"Logistic Regression\")","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:08.553590Z","iopub.execute_input":"2023-07-12T04:57:08.554407Z","iopub.status.idle":"2023-07-12T04:57:08.576508Z","shell.execute_reply.started":"2023-07-12T04:57:08.554356Z","shell.execute_reply":"2023-07-12T04:57:08.574895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = log_model.predict(x_test)\n\ncm = confusion_matrix(y_test, pred)\n\nsns.heatmap(cm,annot=True)\n\nplt.title(\"confusion matrix for Logistic regression\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:08.582031Z","iopub.execute_input":"2023-07-12T04:57:08.583148Z","iopub.status.idle":"2023-07-12T04:57:08.998310Z","shell.execute_reply.started":"2023-07-12T04:57:08.583104Z","shell.execute_reply":"2023-07-12T04:57:08.997100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'>SVM</h1></center>\n","metadata":{}},{"cell_type":"markdown","source":"**Support Vector Machines (SVMs) are powerful supervised machine learning algorithms used for classification and regression tasks. SVMs are particularly effective in solving binary classification problems, but they can also be extended to handle multi-class classification.**\n\n**The key idea behind SVMs is to find an optimal hyperplane that separates the data points of different classes in the feature space. The hyperplane is chosen such that the margin, the distance between the hyperplane and the closest data points of each class (known as support vectors), is maximized.**\n\n**However, SVMs also have some considerations:**\n\n**Computational complexity: Training an SVM can be computationally expensive, especially when dealing with large datasets. The runtime complexity is generally O(n^2) or O(n^3), where n is the number of training samples.**\n\n**Parameter tuning: SVMs have various hyperparameters, such as the kernel type, regularization parameter, and kernel-specific parameters. Proper parameter tuning is crucial to obtain optimal performance.**\n\n**Sensitivity to data scaling: SVMs are sensitive to the scale of the features. It is generally recommended to scale the features before training an SVM to ensure balanced influence from all features.**","metadata":{}},{"cell_type":"code","source":"start = time.time()\n\nsvc_model=SVC()\n\nsvc_model.fit(x_train,y_train)\n\nprint(svc_model.score(x_test,y_test))\n\nend=time.time()\n\nprint(\"Time required for code is\",end-start)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:09.000241Z","iopub.execute_input":"2023-07-12T04:57:09.000985Z","iopub.status.idle":"2023-07-12T04:57:41.344235Z","shell.execute_reply.started":"2023-07-12T04:57:09.000940Z","shell.execute_reply":"2023-07-12T04:57:41.342862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_dict['svc']=end-start","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:41.346083Z","iopub.execute_input":"2023-07-12T04:57:41.346523Z","iopub.status.idle":"2023-07-12T04:57:41.352830Z","shell.execute_reply.started":"2023-07-12T04:57:41.346483Z","shell.execute_reply":"2023-07-12T04:57:41.351454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy.append(svc_model.score(x_test,y_test))\nalgo_name.append(\"SVC\")","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:41.354786Z","iopub.execute_input":"2023-07-12T04:57:41.355188Z","iopub.status.idle":"2023-07-12T04:57:46.572035Z","shell.execute_reply.started":"2023-07-12T04:57:41.355157Z","shell.execute_reply":"2023-07-12T04:57:46.570821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = svc_model.predict(x_test)\n\ncm = confusion_matrix(y_test, pred)\n\nsns.heatmap(cm,annot=True)\n\nplt.title(\"confusion matrix for svc\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:46.573583Z","iopub.execute_input":"2023-07-12T04:57:46.573993Z","iopub.status.idle":"2023-07-12T04:57:52.088423Z","shell.execute_reply.started":"2023-07-12T04:57:46.573955Z","shell.execute_reply":"2023-07-12T04:57:52.087170Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'>Decision Tree Classifier</h1></center>\n","metadata":{}},{"cell_type":"markdown","source":"**A Decision Tree Classifier is a supervised machine learning algorithm that is commonly used for classification tasks. It builds a model in the form of a tree structure that makes decisions based on the features of the input data.**\n\n**However, decision trees also have some considerations:**\n\n**Overfitting: Decision trees can be prone to overfitting, especially if the tree is allowed to grow too deep or if the training data has noise or outliers. Proper pruning and regularization techniques can mitigate this issue.**\n\n**Lack of robustness: Decision trees are sensitive to small variations in the training data, which can lead to different tree structures. Ensemble methods like Random Forests or Gradient Boosting can be used to address this limitation.**","metadata":{}},{"cell_type":"code","source":"start = time.time()\n\ndtree_model=DecisionTreeClassifier()\n\ndtree_model.fit(x_train,y_train)\n\nprint(dtree_model.score(x_test,y_test))\n\nend=time.time()\n\nprint(\"Time required for code is\",end-start)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:52.090188Z","iopub.execute_input":"2023-07-12T04:57:52.090575Z","iopub.status.idle":"2023-07-12T04:57:52.430332Z","shell.execute_reply.started":"2023-07-12T04:57:52.090542Z","shell.execute_reply":"2023-07-12T04:57:52.428899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_dict['Decision tree']=end-start","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:52.432001Z","iopub.execute_input":"2023-07-12T04:57:52.432335Z","iopub.status.idle":"2023-07-12T04:57:52.437324Z","shell.execute_reply.started":"2023-07-12T04:57:52.432306Z","shell.execute_reply":"2023-07-12T04:57:52.436201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy.append(dtree_model.score(x_test,y_test))\nalgo_name.append(\"Decision tree classifier\")","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:52.439401Z","iopub.execute_input":"2023-07-12T04:57:52.439985Z","iopub.status.idle":"2023-07-12T04:57:52.455579Z","shell.execute_reply.started":"2023-07-12T04:57:52.439946Z","shell.execute_reply":"2023-07-12T04:57:52.454485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = dtree_model.predict(x_test)\n\ncm = confusion_matrix(y_test, pred)\n\nsns.heatmap(cm,annot=True)\n\nplt.title(\"confusion matrix for  decision tree\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:52.457385Z","iopub.execute_input":"2023-07-12T04:57:52.457885Z","iopub.status.idle":"2023-07-12T04:57:52.811024Z","shell.execute_reply.started":"2023-07-12T04:57:52.457845Z","shell.execute_reply":"2023-07-12T04:57:52.808679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'>Gaussian NB</h1></center>\n","metadata":{}},{"cell_type":"markdown","source":"**The Gaussian Naive Bayes classifier is a variant of the Naive Bayes algorithm that assumes a Gaussian (normal) distribution for the continuous features in the dataset. It is a probabilistic classifier that applies Bayes' theorem with the assumption of independence between features (hence the \"naive\" assumption) to make predictions.**","metadata":{}},{"cell_type":"code","source":"start = time.time()\n\nbayes_model = GaussianNB()  \n\nbayes_model.fit(x_train, y_train)\n\nprint(bayes_model.score(x_test,y_test))\n\nend=time.time()\n\nprint(\"Time required for code is\",end-start)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:52.813163Z","iopub.execute_input":"2023-07-12T04:57:52.813640Z","iopub.status.idle":"2023-07-12T04:57:52.842048Z","shell.execute_reply.started":"2023-07-12T04:57:52.813598Z","shell.execute_reply":"2023-07-12T04:57:52.840694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_dict['GaussianNB']=end-start","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:52.844103Z","iopub.execute_input":"2023-07-12T04:57:52.844485Z","iopub.status.idle":"2023-07-12T04:57:52.850033Z","shell.execute_reply.started":"2023-07-12T04:57:52.844457Z","shell.execute_reply":"2023-07-12T04:57:52.848739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy.append(bayes_model.score(x_test,y_test))\nalgo_name.append(\"naive bayes classifier\")","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:52.851494Z","iopub.execute_input":"2023-07-12T04:57:52.851839Z","iopub.status.idle":"2023-07-12T04:57:52.867390Z","shell.execute_reply.started":"2023-07-12T04:57:52.851809Z","shell.execute_reply":"2023-07-12T04:57:52.866099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = bayes_model.predict(x_test)\n\ncm = confusion_matrix(y_test, pred)\n\nsns.heatmap(cm,annot=True)\n\nplt.title(\"confusion matrix for  naive bayes\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:52.868871Z","iopub.execute_input":"2023-07-12T04:57:52.869234Z","iopub.status.idle":"2023-07-12T04:57:53.216527Z","shell.execute_reply.started":"2023-07-12T04:57:52.869203Z","shell.execute_reply":"2023-07-12T04:57:53.215342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'> K-Nearest Neighbors </h1></center>\n","metadata":{}},{"cell_type":"markdown","source":"**The k-Nearest Neighbors (k-NN) classifier is a supervised machine learning algorithm used for classification tasks. It is a non-parametric method that makes predictions based on the similarity between the new data point and its k nearest neighbors in the training set.**\n\n**Feature scaling: It is important to scale the features to ensure that no single feature dominates the distance calculation. Features with larger scales can otherwise have a disproportionate influence on the nearest neighbor selection.**\n\n**Choice of distance metric: The choice of distance metric can significantly impact the performance of the k-NN classifier. Different distance metrics may be more appropriate depending on the nature of the data and the problem domain.**\n\n**Curse of dimensionality: The k-NN classifier can be sensitive to the curse of dimensionality, where the performance degrades as the number of dimensions (features) increases. In high-dimensional spaces, the notion of proximity becomes less meaningful, and the classifier may struggle to find meaningful neighbors.**","metadata":{}},{"cell_type":"code","source":"start = time.time()\n\nk_model= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  \n\nk_model.fit(x_train, y_train)  \n\nprint(k_model.score(x_test,y_test))\n\nend=time.time()\n\nprint(\"Time required for code is\",end-start)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:53.218157Z","iopub.execute_input":"2023-07-12T04:57:53.218460Z","iopub.status.idle":"2023-07-12T04:57:54.562806Z","shell.execute_reply.started":"2023-07-12T04:57:53.218433Z","shell.execute_reply":"2023-07-12T04:57:54.561584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_dict['KNeighborsClassifier']=end-start","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:54.564628Z","iopub.execute_input":"2023-07-12T04:57:54.565033Z","iopub.status.idle":"2023-07-12T04:57:54.571176Z","shell.execute_reply.started":"2023-07-12T04:57:54.564975Z","shell.execute_reply":"2023-07-12T04:57:54.569707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy.append(k_model.score(x_test,y_test))\nalgo_name.append(\"naive bayes classifier\")","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:54.572664Z","iopub.execute_input":"2023-07-12T04:57:54.573066Z","iopub.status.idle":"2023-07-12T04:57:55.866322Z","shell.execute_reply.started":"2023-07-12T04:57:54.573003Z","shell.execute_reply":"2023-07-12T04:57:55.865081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = k_model.predict(x_test)\n\ncm = confusion_matrix(y_test, pred)\n\nsns.heatmap(cm,annot=True)\n\nplt.title(\"confusion matrix for  k neighbours classifier\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:55.868215Z","iopub.execute_input":"2023-07-12T04:57:55.868735Z","iopub.status.idle":"2023-07-12T04:57:57.502448Z","shell.execute_reply.started":"2023-07-12T04:57:55.868688Z","shell.execute_reply":"2023-07-12T04:57:57.501125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'> Random Forest Classifier </h1></center>\n","metadata":{}},{"cell_type":"markdown","source":"**The Random Forest Classifier is a supervised machine learning algorithm that is an ensemble of decision trees. It combines the predictions of multiple individual decision trees to make a final prediction, typically for a classification task.**","metadata":{}},{"cell_type":"code","source":"time_dict_bost={} #dictionary for boosting ","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:57.503962Z","iopub.execute_input":"2023-07-12T04:57:57.504292Z","iopub.status.idle":"2023-07-12T04:57:57.509600Z","shell.execute_reply.started":"2023-07-12T04:57:57.504264Z","shell.execute_reply":"2023-07-12T04:57:57.508533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nrf_model= RandomForestClassifier() \n\nrf_model.fit(x_train, y_train)  \n\nprint(rf_model.score(x_test,y_test))\n\nend=time.time()\n\nprint(\"Time required for code is\",end-start)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:57:57.511328Z","iopub.execute_input":"2023-07-12T04:57:57.511773Z","iopub.status.idle":"2023-07-12T04:58:04.769608Z","shell.execute_reply.started":"2023-07-12T04:57:57.511732Z","shell.execute_reply":"2023-07-12T04:58:04.768233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_dict_bost['RandomForest Classifier']=end-start","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:04.771211Z","iopub.execute_input":"2023-07-12T04:58:04.771554Z","iopub.status.idle":"2023-07-12T04:58:04.777357Z","shell.execute_reply.started":"2023-07-12T04:58:04.771524Z","shell.execute_reply":"2023-07-12T04:58:04.775826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy.append(rf_model.score(x_test,y_test))\nalgo_name.append(\"random forest classifier\")","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:04.778824Z","iopub.execute_input":"2023-07-12T04:58:04.779163Z","iopub.status.idle":"2023-07-12T04:58:05.006839Z","shell.execute_reply.started":"2023-07-12T04:58:04.779135Z","shell.execute_reply":"2023-07-12T04:58:05.005549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = rf_model.predict(x_test)\n\ncm = confusion_matrix(y_test, pred)\n\nsns.heatmap(cm,annot=True)\n\nplt.title(\"confusion matrix for Random forest classifier\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:05.008779Z","iopub.execute_input":"2023-07-12T04:58:05.009275Z","iopub.status.idle":"2023-07-12T04:58:05.570956Z","shell.execute_reply.started":"2023-07-12T04:58:05.009232Z","shell.execute_reply":"2023-07-12T04:58:05.569477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'> Ada Boost  Classifier </h1></center>\n","metadata":{}},{"cell_type":"markdown","source":"**AdaBoost (Adaptive Boosting) is a machine learning algorithm that belongs to the family of ensemble learning methods. It is particularly effective in solving binary classification problems but can be extended to multi-class classification as well.**\n\n**AdaBoost has several advantages:**\n\n**Improved accuracy: AdaBoost focuses on difficult-to-classify samples by assigning higher weights to misclassified samples during training. This helps in improving the overall accuracy of the model.**\n\n**Handling of complex datasets: AdaBoost can effectively handle datasets with complex relationships and overlapping classes.**\n\n**No need for feature scaling: AdaBoost is not sensitive to the scale of the features, so feature scaling is not required.**","metadata":{}},{"cell_type":"code","source":"start = time.time()\n\nadaboost = AdaBoostClassifier() \n\nadaboost.fit(x_train, y_train)  \n\nprint(adaboost.score(x_test,y_test))\n\nend=time.time()\n\nprint(\"Time required for code is\",end-start)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:05.583328Z","iopub.execute_input":"2023-07-12T04:58:05.583774Z","iopub.status.idle":"2023-07-12T04:58:07.525130Z","shell.execute_reply.started":"2023-07-12T04:58:05.583743Z","shell.execute_reply":"2023-07-12T04:58:07.523688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_dict_bost['Ada boost Classifier']=end-start","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:07.526684Z","iopub.execute_input":"2023-07-12T04:58:07.527024Z","iopub.status.idle":"2023-07-12T04:58:07.532584Z","shell.execute_reply.started":"2023-07-12T04:58:07.526983Z","shell.execute_reply":"2023-07-12T04:58:07.531477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy.append(adaboost.score(x_test,y_test))\nalgo_name.append(\"ada boost classifier\")","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:07.533786Z","iopub.execute_input":"2023-07-12T04:58:07.534715Z","iopub.status.idle":"2023-07-12T04:58:07.625173Z","shell.execute_reply.started":"2023-07-12T04:58:07.534681Z","shell.execute_reply":"2023-07-12T04:58:07.624063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = adaboost.predict(x_test)\n\ncm = confusion_matrix(y_test, pred)\n\nsns.heatmap(cm,annot=True)\n\nplt.title(\"confusion matrix for Ada boost classifier\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:07.626988Z","iopub.execute_input":"2023-07-12T04:58:07.627783Z","iopub.status.idle":"2023-07-12T04:58:08.071579Z","shell.execute_reply.started":"2023-07-12T04:58:07.627719Z","shell.execute_reply":"2023-07-12T04:58:08.070219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'> Gradient Boosting</h1></center>\n","metadata":{}},{"cell_type":"markdown","source":"**Gradient Boosting is a machine learning technique used for both regression and classification tasks. It is an ensemble method that combines multiple weak learners, typically decision trees, to create a strong predictive model. The gradient boosting algorithm iteratively improves the model by focusing on the mistakes made by the previous weak learners.**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nimport time\n\nstart = time.time()\n\nGB = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\nGB.fit(x_train, y_train)\n\nend = time.time()\nexecution_time = end - start\n\nprint(\"Execution time:\", execution_time)\n\naccuracy1 = GB.score(x_test, y_test)\nprint(\"Accuracy:\", accuracy1)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:08.073378Z","iopub.execute_input":"2023-07-12T04:58:08.073800Z","iopub.status.idle":"2023-07-12T04:58:10.385471Z","shell.execute_reply.started":"2023-07-12T04:58:08.073767Z","shell.execute_reply":"2023-07-12T04:58:10.384301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_dict_bost['Gradient boost Classifier']=end-start","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:10.387115Z","iopub.execute_input":"2023-07-12T04:58:10.387783Z","iopub.status.idle":"2023-07-12T04:58:10.394323Z","shell.execute_reply.started":"2023-07-12T04:58:10.387740Z","shell.execute_reply":"2023-07-12T04:58:10.392797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy.append(GB.score(x_test,y_test))\nalgo_name.append(\"gradient  boost classifier\")","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:10.396254Z","iopub.execute_input":"2023-07-12T04:58:10.396614Z","iopub.status.idle":"2023-07-12T04:58:10.418741Z","shell.execute_reply.started":"2023-07-12T04:58:10.396584Z","shell.execute_reply":"2023-07-12T04:58:10.417862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = GB.predict(x_test)\n\ncm = confusion_matrix(y_test, pred)\n\nsns.heatmap(cm,annot=True)\n\nplt.title(\"confusion matrix for Gradient boost boost classifier\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:10.420087Z","iopub.execute_input":"2023-07-12T04:58:10.420616Z","iopub.status.idle":"2023-07-12T04:58:11.324022Z","shell.execute_reply.started":"2023-07-12T04:58:10.420586Z","shell.execute_reply":"2023-07-12T04:58:11.323122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'> Un-supervised learning</h1></center>\n","metadata":{}},{"cell_type":"code","source":"y_train=encoder.fit_transform(y_train)\nreshaped_array = y_train.reshape((39785, 1)) #converting array into 2-dim for k menas","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:11.325377Z","iopub.execute_input":"2023-07-12T04:58:11.325902Z","iopub.status.idle":"2023-07-12T04:58:11.332876Z","shell.execute_reply.started":"2023-07-12T04:58:11.325872Z","shell.execute_reply":"2023-07-12T04:58:11.331763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wcss=[]\nfor k in range(1, 10):\n    kmeans = KMeans(n_clusters=k)\n    kmeans.fit(reshaped_array)\n    wcss.append(kmeans.inertia_) \n    \n    \n# Plot the WCSS values against k\nplt.figure(figsize=(10,5))\nplt.plot(range(1, 10), wcss)\nplt.title('Elbow Method')\nplt.xlabel('Number of Clusters (k)')\nplt.ylabel('WCSS')\nplt.show()    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:11.334638Z","iopub.execute_input":"2023-07-12T04:58:11.334996Z","iopub.status.idle":"2023-07-12T04:58:12.590295Z","shell.execute_reply.started":"2023-07-12T04:58:11.334967Z","shell.execute_reply":"2023-07-12T04:58:12.589167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train=encoder.fit_transform(y_train)\nreshaped_array_test = y_train.reshape((39785, 1))\npredicted_labels = pd.DataFrame(kmeans.predict(reshaped_array_test))","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:12.591849Z","iopub.execute_input":"2023-07-12T04:58:12.592324Z","iopub.status.idle":"2023-07-12T04:58:12.606173Z","shell.execute_reply.started":"2023-07-12T04:58:12.592281Z","shell.execute_reply":"2023-07-12T04:58:12.604880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_labels.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:12.608582Z","iopub.execute_input":"2023-07-12T04:58:12.609257Z","iopub.status.idle":"2023-07-12T04:58:12.618732Z","shell.execute_reply.started":"2023-07-12T04:58:12.609222Z","shell.execute_reply":"2023-07-12T04:58:12.617206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\npredicted_labels.value_counts().plot(kind=\"bar\");\nplt.xlabel(\"Values\")\nplt.title(\"Predicted output using k means algorithms\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:12.620528Z","iopub.execute_input":"2023-07-12T04:58:12.621512Z","iopub.status.idle":"2023-07-12T04:58:12.920950Z","shell.execute_reply.started":"2023-07-12T04:58:12.621479Z","shell.execute_reply":"2023-07-12T04:58:12.920190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.bar( algo_name,accuracy, color ='black',\n        width = 0.5)\nplt.ylabel(\"Accuracy \")\nplt.xticks(rotation=45)\nplt.title(\"ACCUARCY OF BAGGING ALGORITHMS\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:12.922326Z","iopub.execute_input":"2023-07-12T04:58:12.922914Z","iopub.status.idle":"2023-07-12T04:58:13.298178Z","shell.execute_reply.started":"2023-07-12T04:58:12.922881Z","shell.execute_reply":"2023-07-12T04:58:13.297058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"value=time_dict.values()\nkey=time_dict.keys()\na=[]\nb=[]\nfor val in value:\n    a.append(val)\n    \nfor k in key:\n    b.append(k)    \n","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:13.299579Z","iopub.execute_input":"2023-07-12T04:58:13.300135Z","iopub.status.idle":"2023-07-12T04:58:13.305731Z","shell.execute_reply.started":"2023-07-12T04:58:13.300103Z","shell.execute_reply":"2023-07-12T04:58:13.304782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.bar( b,a, color ='black',\n        width = 0.5)\nplt.ylabel(\"time in seconds\")\nplt.title(\"TIME REQURED FOR BAGGING ALGORITHMS\")","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:13.307040Z","iopub.execute_input":"2023-07-12T04:58:13.307853Z","iopub.status.idle":"2023-07-12T04:58:13.694364Z","shell.execute_reply.started":"2023-07-12T04:58:13.307812Z","shell.execute_reply":"2023-07-12T04:58:13.693382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SVC required highest time training the model among all classifiers.**","metadata":{}},{"cell_type":"code","source":"value=time_dict_bost.values()\nkey=time_dict_bost.keys()\na=[]\nb=[]\nfor val in value:\n    a.append(val)\n    \nfor k in key:\n    b.append(k)   ","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:13.695734Z","iopub.execute_input":"2023-07-12T04:58:13.696102Z","iopub.status.idle":"2023-07-12T04:58:13.702365Z","shell.execute_reply.started":"2023-07-12T04:58:13.696072Z","shell.execute_reply":"2023-07-12T04:58:13.701166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.bar( b,a, color ='black',\n        width = 0.5)\nplt.ylabel(\"time in seconds\")\nplt.title(\"TIME REQURED FOR BOOSTING ALGORITHMS\");","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:13.703995Z","iopub.execute_input":"2023-07-12T04:58:13.705101Z","iopub.status.idle":"2023-07-12T04:58:14.018734Z","shell.execute_reply.started":"2023-07-12T04:58:13.705063Z","shell.execute_reply":"2023-07-12T04:58:14.017518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Gradient boosting take least time for model training among all boosting algorithms**","metadata":{}},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'>Data Sampling </h1></center>\n","metadata":{}},{"cell_type":"markdown","source":"**Random sampling is a technique used to select a subset of data points from a larger dataset, where each data point has an equal chance of being selected. It is commonly employed in statistics and machine learning for tasks such as training set creation, model evaluation, and generating random samples for analysis.**","metadata":{}},{"cell_type":"code","source":"y_train\ntype(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:14.020000Z","iopub.execute_input":"2023-07-12T04:58:14.020392Z","iopub.status.idle":"2023-07-12T04:58:14.029376Z","shell.execute_reply.started":"2023-07-12T04:58:14.020360Z","shell.execute_reply":"2023-07-12T04:58:14.027883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ros = RandomOverSampler(random_state=42)\n\n# Perform oversampling\nX_resampled, y_resampled = ros.fit_resample(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:14.031289Z","iopub.execute_input":"2023-07-12T04:58:14.031618Z","iopub.status.idle":"2023-07-12T04:58:14.076682Z","shell.execute_reply.started":"2023-07-12T04:58:14.031590Z","shell.execute_reply":"2023-07-12T04:58:14.075430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nbayes_model = GaussianNB()  \n\nbayes_model.fit(X_resampled, y_resampled)\n\nprint(bayes_model.score(x_test,y_test))\n\nend=time.time()\n\nprint(\"Time required for code is\",end-start)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:14.078613Z","iopub.execute_input":"2023-07-12T04:58:14.078933Z","iopub.status.idle":"2023-07-12T04:58:14.125865Z","shell.execute_reply.started":"2023-07-12T04:58:14.078906Z","shell.execute_reply":"2023-07-12T04:58:14.124737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nimport time\n\nstart = time.time()\n\nGB = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\nGB.fit(X_resampled, y_resampled)\n\nend = time.time()\nexecution_time = end - start\n\nprint(\"Execution time:\", execution_time)\n\naccuracy1 = GB.score(x_test, y_test)\nprint(\"Accuracy:\", accuracy1)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T04:58:14.127386Z","iopub.execute_input":"2023-07-12T04:58:14.128216Z","iopub.status.idle":"2023-07-12T04:58:18.238915Z","shell.execute_reply.started":"2023-07-12T04:58:14.128173Z","shell.execute_reply":"2023-07-12T04:58:18.237757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****With pca the accuracy is 84.00 for the both GuassinNB and gradientboosting****","metadata":{}},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'> PCA </h1></center>\n","metadata":{}},{"cell_type":"markdown","source":"**Principal Component Analysis (PCA) is a technique used for dimensionality reduction and data visualization. It is commonly used in data preprocessing and exploratory data analysis. PCA transforms a dataset into a new set of variables, called principal components, which are linear combinations of the original features. These principal components are ordered in terms of their ability to explain the variance in the data.**","metadata":{}},{"cell_type":"code","source":"pca = PCA(n_components=4)\nX_pca_train = pca.fit_transform(x_train)\nX_pca_test = pca.fit_transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T05:12:25.006886Z","iopub.execute_input":"2023-07-12T05:12:25.008453Z","iopub.status.idle":"2023-07-12T05:12:25.418496Z","shell.execute_reply.started":"2023-07-12T05:12:25.008401Z","shell.execute_reply":"2023-07-12T05:12:25.416123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nbayes_model = GaussianNB()  \n\nbayes_model.fit(X_pca_train, y_train)\n\nprint(bayes_model.score(X_pca_test,y_test))\n\nend=time.time()\n\nprint(\"Time required for code is\",end-start)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T05:12:27.056109Z","iopub.execute_input":"2023-07-12T05:12:27.056548Z","iopub.status.idle":"2023-07-12T05:12:27.081945Z","shell.execute_reply.started":"2023-07-12T05:12:27.056518Z","shell.execute_reply":"2023-07-12T05:12:27.081017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nimport time\n\nstart = time.time()\n\nGB = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\nGB.fit(X_pca_train, y_train)\n\nend = time.time()\nexecution_time = end - start\n\nprint(\"Execution time:\", execution_time)\n\naccuracy1 = GB.score(X_pca_test, y_test)\nprint(\"Accuracy:\", accuracy1)","metadata":{"execution":{"iopub.status.busy":"2023-07-12T05:12:29.855915Z","iopub.execute_input":"2023-07-12T05:12:29.856341Z","iopub.status.idle":"2023-07-12T05:12:32.914303Z","shell.execute_reply.started":"2023-07-12T05:12:29.856311Z","shell.execute_reply":"2023-07-12T05:12:32.913221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.scatter(X_pca_train[:, 0], X_pca_train[:, 1], c=y_train)\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.title('PCA')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-12T05:15:22.106142Z","iopub.execute_input":"2023-07-12T05:15:22.106675Z","iopub.status.idle":"2023-07-12T05:15:23.407103Z","shell.execute_reply.started":"2023-07-12T05:15:22.106622Z","shell.execute_reply":"2023-07-12T05:15:23.406058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**With pca the accuracy is 88.00 for the both GuassinNB and gradientboosting**","metadata":{}},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'>Conclusion:- Gaussin NB required less time for training model than any other algorithms and have accuracy around 91%.Data resampling reduce the accuracy to 84% and in case of PCA also reduced accuracy towards 88% .Gradinet boosting have goood training time in boosting algorithms</h1></center>\n","metadata":{}},{"cell_type":"markdown","source":"<center><h1 style='background-color:#99ccff;padding:10px;font-family:courier'> If YOU LIKE,PLEASE UPVOTES </h1></center>\n","metadata":{}}]}